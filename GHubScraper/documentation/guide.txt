User Guide for David's GithubScraper_v2 (old, simple scraper upgraded as a bonus)

Contents:
I. Specification
II. Implementation
III. Environment

I. Specification:
    1, We need a script that collect some information about the public github repositories from
        https://github.com/github.
    2, We need the following properties of each repositories:
        - Url of the repo
        - Short description
        - Language of implementation (programming language)
        - The list of the tags
    3, We need the result to be in a csv file.
    4, Documentation
        We need a documentation that describes how we can build the environment and how to run
        the script.

II. Implementation:
    The the whole codebase resides in GHubScraper\solution\main.py.
        (for a simple solution please find old/old.py)

    Structure:
        1 Class: Main
            2 dunder methods: init and str
            3 user defined functions: check_url, get_first_page, scraping
        Run logic with argparsing. (# Could be more elegant from a different file)

    Justification:
        Why only one class?
            For a simple application like this it would be an overkill to separate logic into smaller pieces,
            decreasing readability. Simple is better than complex.
        Why more complex than specified?
            The original code did the job with minor errors and faulty cases, I didn't want to complete my task
            by adding 5 more lines and nothing else.
            Also, it feels more complete this way.

    Functionality:
        Application explanation:
            check_url:
              We can initialize main with various arguments through parsing: -f "outputfilename", -u "url or username",
              -n "username". With different validation methods we make sure we get a valid "https://github.com/username"
              url address. Leaving arguments blank gives default parameters (according to specification), giving bad
              parameters result in waiting for user input until a valid github username is presented. Checking validity
              by http responses being less than 300 (not moved, not found, forbidden).
              # Update: No more url checking, switched to username handling only.
            get_first_page:
              This function does two things:
              First, get the number of pages with a minimalistic request to minimise unnecessary
              network traffic. If we can't find page number references in the "sauce" we assume the user's repository is
              only one pages long. (more on why in next section)
              Secondly, creates output file in .csv format with utf-8 encoding and writes first row for columns.
              (There were many errors without explicitly enforcing utf-8 everywhere.)
            scraping:
              Iterating through the pages one by one, with a progressbar included for fanciness.
              If our target user has only one page, we change url to "tab=repositories", otherwise we use our iteration
              number "i", and add it to the url every turn.
              We get all repository blocks on the page and then try to get the info out line by line for each block.
              Making sure we don't get Nones, and adding whitespaces instead so the csv will recognize them still as a
              value. Tags we add to a list.
              And we're trying to catch Unicode and Type errors, just in case..

        Running the application:
            (Written and tested on Windows 10 Home.. I'm sorry i know..)

            Run the virtual environment with activating venv/Scripts/activate
            Open a terminal or cmd in GHubScraper folder and install requirements with the following script:
            ~pip install -r requirements.txt

            Three different options tested:
              cmd/terminal:
                Navigate to the project folder. (lensa_v2/GHubScraper/solution)
                  ~python main.py -f "outputfile" -n "username" -u "https://github.com/username"
                Optional arguments. Leave them for defaults.
                (If you give both username and url, username will be used), and the name of the output file -f .
                # Update, url can't be given anymore, will be stored as unknown argument.

              ide:
                Open main.py and run. Can give argument parameters at the instantiation of Main:
                  Main(username="name", output_file="file").

              python console:
                import sys
                import os
                sys.prefix -to check if we're in the venv.
                sys.argv = ["randomthing","-n username" "-f output_file_name"]
                (running without arguments will trigger defaults, bad arguments trigger user input.)
                # inside pycharm's python console:
                execfile(os.getcwd() + '\GHubScraper\solution\main.py')
                # on windows cmd:
                exec(open(os.getcwd() + '\GHubScraper\solution\main.py').read())

              pyinstaller:
                To make it easy for poor windows users pyinstaller is included
                in venv. After activating it, use ~pyinstaller --onefile main.py
                Now you can use it simply by running the newly created
                dist/main.exe

        Results:
            No matter the method, results are saved in solution/results folder which is next to the main.py file.


III. Environment:
    The base interpreter is:
      Python 3.7.2 (default, Jan  2 2019, 17:07:39) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32
    Step by step:
        1. Download codebase from my github page, which if you're reading this you've probably done already.
        2. Activate python's virtual environment (assuming you have python installed)(only on windows, on others you have
            to install requirements to your env.)
            or Install required packages with: pip install -r requirements.txt (recommended)
        3. Choose favorite execution method. (


UPDATE 1: Eliminated url acceptance and validation from the code, working with usernames only. More simple, clean code.

DOCKER:
    On windows 10 home I've had difficulties running docker so here is a "successful build" on docker hub,
    I wasn't able to test it. Download and try at your own risk. ~docker pull daveyo89/homework:latest